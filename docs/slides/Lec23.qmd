---
title: "More Tidymodels"
subtitle: "Lecture 23"
author: "Dr. Colin Rundel"
footer: "Sta 523 - Fall 2023"
format:
  revealjs:
    theme: slides.scss
    transition: fade
    slide-number: true
    self-contained: true
execute: 
  echo: true
  message: true
---

```{r setup}
#| message: False
#| warning: False
#| include: False

knitr::opts_chunk$set(
  fig.align = "center", fig.retina = 2, dpi = 150,
  out.width = "100%"
)

library(tidymodels)
library(tidyverse)
library(patchwork)

ggplot2::theme_set(ggplot2::theme_bw())

options(width=85)
```

#

![](imgs/hex_tidymodels.png){fig-align="center" width="50%"}


## Hotels Data

Original data from [Antonio, Almeida, and Nunes (2019)](https://doi.org/10.1016/j.dib.2018.11.126), [Data dictionary](https://github.com/rfordatascience/tidytuesday/tree/master/data/2020/2020-02-11#data-dictionary)


```{r}
hotels = read_csv(
  'https://tidymodels.org/start/case-study/hotels.csv'
) |>
  mutate(
    across(where(is.character), as.factor)
  )
```

::: {.aside}
This version of the data is slightly modified from the original data - see [gist](https://gist.github.com/topepo/05a74916c343e57a71c51d6bc32a21ce) for the cleanup steps
:::

## The data

```{r}
#| include: false
options(width=95)
```

::: {.small}
```{r}
glimpse(hotels)
```
:::

```{r}
#| include: false
options(width=60)
```

## The model

Our goal is to develop a predictive model that is able to predict whether a booking will include children or not based on the other characteristics of the booking.

. . .

```{r}
hotels |>
  count(children) |>
  mutate(prop = n/sum(n))
```


## Clustering the test/train split

:::: {.columns .small}
::: {.column width='50%'}
```{r}
set.seed(123)

splits = initial_split(
  hotels, strata = children
)

hotel_train = training(splits)
hotel_test = testing(splits)
```

```{r}
dim(hotel_train)
dim(hotel_test)
```
:::

::: {.column width='50%' .fragment}
```{r}
hotel_train |>
  count(children) |>
  mutate(prop = n/sum(n))

hotel_test |>
  count(children) |>
  mutate(prop = n/sum(n))
```
:::
::::

## Logistic Regression model

::: {.small}
```{r}
show_engines("logistic_reg")
```
:::

. . .

::: {.small}
```{r}
lr_model = logistic_reg() |>
  set_engine("glm")
```

```{r}
translate(lr_model)
```
:::

## Recipe

::: {.small}
```{r}
holidays = c("AllSouls", "AshWednesday", "ChristmasEve", "Easter", 
              "ChristmasDay", "GoodFriday", "NewYearsDay", "PalmSunday")

lr_recipe = recipe(children ~ ., data = hotel_train) |> 
  step_date(arrival_date) |> 
  step_holiday(arrival_date, holidays = holidays) |> 
  step_rm(arrival_date) |> 
  step_rm(country) |>
  step_dummy(all_nominal_predictors()) |> 
  step_zv(all_predictors())

lr_recipe
```
:::

##

```{r include=FALSE}
options(width=100)
options(tibble.width = 100)
```

::: {.small}
```{r}
lr_recipe |>
  prep() |>
  bake(new_data = hotel_train)
```
:::

```{r include=FALSE}
options(width=60)
options(tibble.width = 60)
```

## Workflow

::: {.small}
```{r}
( lr_work = workflow() |>
    add_model(lr_model) |>
    add_recipe(lr_recipe) 
)
```
:::

## Fit

::: {.small}
```{r}
( lr_fit = lr_work |>
    fit(data = hotel_train) )
```
:::

## Logistic regression predictions

:::: {.columns}
::: {.column width='50%'}
```{r}
( lr_train_perf = lr_fit |>
    augment(new_data = hotel_train) |>
    select(children, starts_with(".pred")) )
```
:::

::: {.column width='50%'}
```{r}
( lr_test_perf = lr_fit |>
    augment(new_data = hotel_test) |>
    select(children, starts_with(".pred")) )
```
:::
::::


## Performance metrics (within-sample)

:::: {.columns .small}
::: {.column width='50%'}
```{r}
conf_mat(lr_train_perf, children, .pred_class)

accuracy(lr_train_perf, children, .pred_class)

precision(lr_train_perf, children, .pred_class)
```
:::

::: {.column width='50%' .fragment}
```{r}
yardstick::roc_curve(
  lr_train_perf,
  children,
  .pred_children
) |>
  autoplot()

roc_auc(lr_train_perf, children, .pred_children)
```
:::
::::

## Performance metrics (out-of-sample)

:::: {.columns .small}
::: {.column width='50%'}
```{r}
conf_mat(lr_test_perf, children, .pred_class)

accuracy(lr_test_perf, children, .pred_class)

precision(lr_test_perf, children, .pred_class)
```
:::

::: {.column width='50%'}
```{r}
  yardstick::roc_curve(
    lr_test_perf,
    children,
    .pred_children
  ) |>
  autoplot()

roc_auc(lr_test_perf, children, .pred_children)
```
:::
::::


## Combining ROC curves

::: {.small}
```{r}
#| output-location: column
lr_train_roc = lr_train_perf |>
  yardstick::roc_curve(
    children, .pred_children
  ) |> 
  mutate(name="logistic - train")

lr_test_roc = lr_test_perf |>
  yardstick::roc_curve(
    children, .pred_children
  ) |> 
  mutate(name="logistic - test")

bind_rows(
  lr_train_roc,
  lr_test_roc
) |>
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = name)) + 
    geom_path(lwd = 1.5, alpha = 0.8) +
    geom_abline(lty = 3) + 
    coord_equal()
```
:::


# Lasso 

## Lasso Model

For this we will be using the `glmnet` package which supports fitting lasso, ridge and elastic net models. 

. . .


::: {.small}
```{r}
lasso_model = logistic_reg(penalty = tune(), mixture = 1) |>
  set_engine("glmnet")
```
:::

* `mixture` determines the type of model fit 
  
  * `1` for Lasso, 
  
  * `0` for Ridge,
  
  * other for elastic net.

* `penalty` is $\lambda$ in the lasso model, scales the penalty for coefficient size.


##

```{r}
lasso_model |> 
  parameters()
```

. . .

```{r}
lasso_model |>
  translate()
```



## Lasso Recipe

Lasso (and Ridge) models are sensitive to the scale of the model features, and so a standard approach is to normalize all features before fitting the model.

::: {.small}
```{r}
lasso_recipe = lr_recipe |>
  step_normalize(all_predictors())
```
:::

. . .

::: {.small}
```{r}
lasso_recipe |>
  prep() |>
  bake(new_data = hotel_train)
```
:::

## Lasso workflow

::: {.small}
```{r}
( lasso_work = workflow() |>
    add_model(lasso_model) |>
    add_recipe(lasso_recipe)
)
```
:::


## v-folds for hyperparameter tuning

```{r}
( hotel_vf = rsample::vfold_cv(hotel_train, v=5, strata = children) )
```

## grid search

::: {.small}
```{r}
#| code-line-numbers: "|1|3|4-6|7|8"
( lasso_grid = lasso_work |>
    tune_grid(
      hotel_vf,
      grid = tibble(
        penalty = 10^seq(-4, -1, length.out = 10)
      ),
      control = control_grid(save_pred = TRUE),
      metrics = metric_set(roc_auc)
    )
)
```
:::

## Results

```{r include=FALSE}
options(width=50)
options(tibble.width = 50)
```

:::: {.columns .small}
::: {.column width='50%'}
```{r}
lasso_grid |>
  collect_metrics()
```
:::

::: {.column width='50%'}
```{r}
lasso_grid |> 
  collect_metrics() |> 
  ggplot(aes(x = penalty, y = mean)) + 
    geom_point() + 
    geom_line() + 
    ylab("Area under the ROC Curve") +
    scale_x_log10(labels = scales::label_number())
```
:::
::::


```{r include=FALSE}
options(width=60)
options(tibble.width = 60)
```

## "Best" models

::: {.small}
```{r}
lasso_grid |>
  show_best("roc_auc", n=10)
```
:::

## "Best" model

::: {.small}
```{r}
( lasso_best = lasso_grid |>
    collect_metrics() |>
    mutate(mean = round(mean, 2)) |>
    arrange(desc(mean), desc(penalty)) |>
    slice(1) )
```
:::

## Extracting predictions

Since we used `control_grid(save_pred = TRUE)` with `tune_grid()` we can recover the predictions for the out-of-sample values for each fold:

::: {.small}
```{r}
( lasso_train_perf = lasso_grid |>
    collect_predictions(parameters = lasso_best) )
```
:::

##

::: {.small}
```{r}
lasso_train_perf |>
  roc_curve(children, .pred_children) |>
  autoplot()

lasso_train_perf |>
  roc_auc(children, .pred_children)
```
:::

## Re-fitting

Typically with a tuned model we will refit using the complete test data and the "best" parameter value(s),

```{r}
lasso_work_tuned = update_model(
  lasso_work, 
  logistic_reg(
    mixture = 1, 
    penalty = lasso_best$penalty
  ) |>
    set_engine("glmnet")
)

lasso_fit = lasso_work_tuned |>
  fit(data=hotel_train)
```


## Test Performance (out-of-sample)

:::: {.columns .small}
::: {.column width='50%'}
```{r}
lasso_test_perf = lasso_fit |>
  augment(new_data = hotel_test) |>
  select(children, starts_with(".pred"))
```

```{r}
conf_mat(lasso_test_perf, children, .pred_class)

accuracy(lasso_test_perf, children, .pred_class)

precision(lasso_test_perf, children, .pred_class)
```
:::

::: {.column width='50%'}
```{r}
lasso_roc = yardstick::roc_curve(
    lasso_test_perf,
    children,
    .pred_children
  ) |>
  mutate(name = "lasso - test")
lasso_roc |>
  autoplot()

roc_auc(lasso_test_perf, children, .pred_children)
```
:::
::::

## Comparing models

```{r out.width="55%", echo=FALSE }
bind_rows(
  lr_test_roc,
  lasso_roc
) |>
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = name)) + 
    geom_path(lwd = 1.5, alpha = 0.8) +
    geom_abline(lty = 3) + 
    coord_equal()
```

# Decision tree

## Decision tree models

```{r}
show_engines("decision_tree")
```

. . .

```{r}
dt_model = decision_tree(
  tree_depth = tune(), 
  min_n = tune(),
  cost_complexity = tune()
) |> 
  set_engine("rpart") |> 
  set_mode("classification")
```

## Recipe & workflow

We skip dummy coding in the recipe as it is not needed by rpart,

```{r}
dt_recipe = recipe(children ~ ., data = hotel_train) |> 
  step_date(arrival_date) |> 
  step_holiday(arrival_date, holidays = holidays) |> 
  step_rm(arrival_date) |>
  step_rm(country)
```

. . .

```{r}
dt_work = workflow() |> 
  add_model(dt_model) |> 
  add_recipe(dt_recipe)
```

## Tuning

:::: {.columns .small}
::: {.column width='50%'}
```{r}
( dt_grid = grid_regular(
    cost_complexity(), 
    tree_depth(), 
    min_n(), 
    levels = 3
) )
```
:::

::: {.column width='50%'}
```{r}
doFuture::registerDoFuture()
future::plan(future::multisession, workers = 8)
```

```{r}
#| cache: true
dt_tune = dt_work |> 
  tune_grid(
    hotel_vf,
    grid = dt_grid,
    control = control_grid(save_pred = TRUE),
    metrics = metric_set(roc_auc)
  )
```
:::
::::

## Tuning results

::: {.small}
```{r}
dt_tune |>
  collect_metrics() |>
  arrange(desc(mean))
```
:::


## "Best" parameters

```{r include=FALSE}
options(width=50)
options(tibble.width = 50)
```

:::: {.columns .small}
::: {.column width='50%'}
```{r}
dt_tune |> 
  show_best(metric = "roc_auc")
```
:::

::: {.column width='50%'}
```{r}
autoplot(dt_tune)
```
:::
::::


```{r include=FALSE}
options(width=60)
options(tibble.width = 60)
```

## Refitting

::: {.small}
```{r}
(dt_best = dt_tune |>
  select_best(metric = "roc_auc"))
```

```{r}
dt_work_tuned = update_model(
  dt_work, 
  decision_tree(
    tree_depth = dt_best$tree_depth,
    min_n = dt_best$min_n,
    cost_complexity = dt_best$cost_complexity
  ) |>
    set_engine("rpart") |>
    set_mode("classification")
)

dt_fit = dt_work_tuned |>
  fit(data=hotel_train)
```
:::

## Model extraction

```{r}
dt_fit |> 
  hardhat::extract_fit_engine() |> 
  plot()
```

## Test Performance (out-of-sample)

:::: {.columns .small}
::: {.column width='50%'}
```{r}
dt_test_perf = dt_fit |>
  augment(new_data = hotel_test) |>
  select(children, starts_with(".pred"))
```

```{r}
conf_mat(dt_test_perf, children, .pred_class)

accuracy(dt_test_perf, children, .pred_class)

precision(dt_test_perf, children, .pred_class)
```
:::

::: {.column width='50%'}
```{r}
dt_roc = yardstick::roc_curve(
    dt_test_perf,
    children,
    .pred_children
  ) |>
  mutate(name = "DT - test")
dt_roc |>
  autoplot()

roc_auc(dt_test_perf, children, .pred_children)
```
:::
::::


## Comparing models

```{r out.width="55%", echo=FALSE }
bind_rows(
  lr_test_roc,
  lasso_roc,
  dt_roc
) |>
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = name)) + 
    geom_path(lwd = 1.5, alpha = 0.8) +
    geom_abline(lty = 3) + 
    coord_equal()
```





# Random Forest

## Random forest models

```{r}
show_engines("rand_forest")
```

. . .

```{r}
rf_model = rand_forest(mtry = tune(), min_n = tune(), trees = 100) |> 
  set_engine("ranger", num.threads = 8) |> 
  set_mode("classification")
```

## Recipe & workflow

We skip dummy coding in the recipe as it is not needed by ranger,

```{r}
rf_recipe = recipe(children ~ ., data = hotel_train) |> 
  step_date(arrival_date) |> 
  step_holiday(arrival_date, holidays = holidays) |> 
  step_rm(arrival_date) |>
  step_rm(country)
```

. . .

```{r}
rf_work = workflow() |> 
  add_model(rf_model) |> 
  add_recipe(rf_recipe)
```

## Tuning - automatic grid search

:::: {.columns .small}
::: {.column width='50%'}
```{r}
#| include: false
future::plan(future::multisession, workers = 1)
```

```{r}
#| cache: true
rf_tune = rf_work |> 
  tune_grid(
    hotel_vf,
    grid = 10,
    control = control_grid(save_pred = TRUE),
    metrics = metric_set(roc_auc)
  )
```
:::

::: {.column width='50%' .fragment}
```{r}
rf_tune |> 
  collect_metrics() |>
  arrange(desc(mean))
```
:::
::::


## "Best" parameters

```{r include=FALSE}
options(width=50)
options(tibble.width = 50)
```

:::: {.columns .small}
::: {.column width='50%'}
```{r}
rf_tune |> 
  show_best(metric = "roc_auc")
```
:::

::: {.column width='50%'}
```{r}
autoplot(rf_tune)
```
:::
::::


```{r include=FALSE}
options(width=60)
options(tibble.width = 60)
```

## Refitting

::: {.small}
```{r}
(rf_best = rf_tune |>
  select_best(metric = "roc_auc"))
```

```{r}
rf_work_tuned = update_model(
  rf_work, 
  rand_forest(
    trees = 100,
    mtry = rf_best$mtry, 
    min_n = rf_best$min_n
  ) |>
    set_engine("ranger", num.threads = 8) |>
    set_mode("classification")
)

rf_fit = rf_work_tuned |>
  fit(data=hotel_train)
```
:::

## Test Performance (out-of-sample)

:::: {.columns .small}
::: {.column width='50%'}
```{r}
rf_test_perf = rf_fit |>
  augment(new_data = hotel_test) |>
  select(children, starts_with(".pred"))
```

```{r}
conf_mat(rf_test_perf, children, .pred_class)

accuracy(rf_test_perf, children, .pred_class)

precision(rf_test_perf, children, .pred_class)
```
:::

::: {.column width='50%'}
```{r}
rf_roc = yardstick::roc_curve(
    rf_test_perf,
    children,
    .pred_children
  ) |>
  mutate(name = "RF - test")
rf_roc |>
  autoplot()

roc_auc(rf_test_perf, children, .pred_children)
```
:::
::::


## Comparing models

```{r out.width="55%", echo=FALSE }
bind_rows(
  lr_test_roc,
  lasso_roc,
  dt_roc,
  rf_roc
) |>
  ggplot(aes(x = 1 - specificity, y = sensitivity, col = name)) + 
    geom_path(lwd = 1.5, alpha = 0.8) +
    geom_abline(lty = 3) + 
    coord_equal()
```
